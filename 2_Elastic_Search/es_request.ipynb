{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200,'scheme': 'http'}])      # Connexion à Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_s/5mkyygcx5flgldzp7jhrqr5w0000gn/T/ipykernel_56492/3730916846.py:1: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = es.search(       # index du premier patient\n",
      "/var/folders/_s/5mkyygcx5flgldzp7jhrqr5w0000gn/T/ipykernel_56492/3730916846.py:1: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  response = es.search(       # index du premier patient\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m response \u001b[39m=\u001b[39m es\u001b[39m.\u001b[39msearch(       \u001b[39m# index du premier patient\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     index\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnotes\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     body\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     }\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m first_name \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39;49m\u001b[39mhits\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mhits\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39m\u001b[39m_source\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mpatient_firstname\u001b[39m\u001b[39m\"\u001b[39m]  \u001b[39m# Récupère le prénom\u001b[39;00m\n\u001b[1;32m     10\u001b[0m last_name \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mhits\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mhits\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39m_source\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mpatient_lastname\u001b[39m\u001b[39m\"\u001b[39m]  \u001b[39m# Récupère le nom de famille\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(first_name, last_name)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "response = es.search(       # index du premier patient\n",
    "    index=\"notes\",\n",
    "    body={\n",
    "        \"query\": {\"match_all\": {}},\n",
    "        \"sort\": {\"date\": {\"order\": \"asc\"}},\n",
    "        \"size\": 1\n",
    "    }\n",
    ")\n",
    "first_name = response[\"hits\"][\"hits\"][0][\"_source\"][\"patient_firstname\"]  # Récupère le prénom\n",
    "last_name = response[\"hits\"][\"hits\"][0][\"_source\"][\"patient_lastname\"]  # Récupère le nom de famille\n",
    "print(first_name, last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient Last Name: Espinoza\n",
      "Patient First Name: Yvonne\n",
      "Text: i can t let go of that sad feeling that i want to be accepted here in this first home of mine\n",
      "Date: 2022-08-15\n",
      "Patient Left: True\n",
      "Emotion: love\n",
      "Confidence: 0.47055910806738893\n",
      "-------------------------\n",
      "Patient Last Name: Grant\n",
      "Patient First Name: Sarah\n",
      "Text: on a boat trip to denmark\n",
      "Date: 2023-02-09\n",
      "Patient Left: False\n",
      "Emotion: happy\n",
      "Confidence: 0.7427826342216294\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_460618/272352446.py:1: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  result = es.search(index=\"notes\", size=2)   #  Recupère les 2 premiers documents\n"
     ]
    }
   ],
   "source": [
    "result = es.search(index=\"notes\", size=2)   #  Recupère les 2 premiers documents\n",
    "\n",
    "for hit in result['hits']['hits']:      # Affiche les notes des résultats parcourus\n",
    "    note = hit['_source']\n",
    "    print(\"Patient Last Name:\", note['patient_lastname'])\n",
    "    print(\"Patient First Name:\", note['patient_firstname'])\n",
    "    print(\"Text:\", note['Text'])\n",
    "    print(\"Date:\", note['date'])\n",
    "    print(\"Patient Left:\", note['patient_left'])\n",
    "    print(\"Emotion:\", note['Emotion'])\n",
    "    print(\"Confidence:\", note['confidence'])\n",
    "    print(\"-------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Répartition des sentiments par patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_distribution(patient_lastname:str, patient_firstname:str) -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "    Prends le prenom et le nom d'un patient, et retourne le nombre de textes et son pourcentage pour chaque emotion\n",
    "    \"\"\"\n",
    "    query = {           #requête\n",
    "        \"size\": 0,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\"term\": {\"patient_firstname\": patient_firstname}},\n",
    "                    {\"term\": {\"patient_lastname\": patient_lastname}}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"sentiment_distribution\": {\n",
    "                \"terms\": {\"field\": \"Emotion\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    result = es.search(index='notes', body=query)\n",
    "    buckets = result[\"aggregations\"][\"sentiment_distribution\"][\"buckets\"]\n",
    "    df = pd.DataFrame(buckets, columns=[\"key\", \"doc_count\"])    # crée le dataframe\n",
    "    total_count = df[\"doc_count\"].sum()\n",
    "    df[\"Percent\"] = round(((df[\"doc_count\"] / total_count) * 100),2)    # Calcul des pourcentages\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_460618/649475586.py:21: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  result = es.search(index='notes', body=query)\n",
      "/tmp/ipykernel_460618/649475586.py:21: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  result = es.search(index='notes', body=query)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>doc_count</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>35</td>\n",
       "      <td>28.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy</td>\n",
       "      <td>34</td>\n",
       "      <td>28.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>26</td>\n",
       "      <td>21.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger</td>\n",
       "      <td>17</td>\n",
       "      <td>14.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "      <td>6</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>surprise</td>\n",
       "      <td>3</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        key  doc_count  Percent\n",
       "0   sadness         35    28.93\n",
       "1     happy         34    28.10\n",
       "2      fear         26    21.49\n",
       "3     anger         17    14.05\n",
       "4      love          6     4.96\n",
       "5  surprise          3     2.48"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_emotion_distribution(last_name, first_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Matrice des sentiments contradictoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_count(es,emotion:str) -> int:\n",
    "    query = {\n",
    "        \"size\": 0,\n",
    "        \"query\": {\n",
    "            \"terms\": {\n",
    "                \"emotion\": [emotion]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es.search(index=\"notes\", body=query)\n",
    "    return response[\"hits\"][\"total\"][\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_460618/527221375.py:10: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = es.search(index=\"notes\", body=query)\n",
      "/tmp/ipykernel_460618/527221375.py:10: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  response = es.search(index=\"notes\", body=query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1617"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_count(es, 'love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matching_entries(es, emotion, text):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\"match\": {\"emotion\": emotion}},\n",
    "                    {\"match\": {\"Text\": text}}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"size\": 0\n",
    "    }\n",
    "\n",
    "    response = es.search(index=\"notes\", body=query)\n",
    "    count = response[\"hits\"][\"total\"][\"value\"]\n",
    "    \n",
    "    return count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_460618/3550042845.py:14: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = es.search(index=\"notes\", body=query)\n",
      "/tmp/ipykernel_460618/3550042845.py:14: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  response = es.search(index=\"notes\", body=query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "5\n",
      "11\n",
      "3\n",
      "15\n",
      "210\n",
      "71\n",
      "26\n",
      "8\n",
      "7\n",
      "16\n",
      "124\n",
      "24\n",
      "5\n",
      "36\n",
      "0\n",
      "6\n",
      "55\n",
      "5\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "16\n",
      "11\n",
      "3\n",
      "5\n",
      "3\n",
      "22\n",
      "47\n",
      "9\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "emotions = ['happy','sadness','anger','surprise','fear','love']\n",
    "\n",
    "for e in emotions:\n",
    "    for e2 in emotions:\n",
    "        print(count_matching_entries(es, e, e2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Mapping' from 'elasticsearch.compat' (/home/apprenant/Projets/NLP/psycho_NLP/venv/lib/python3.10/site-packages/elasticsearch/compat.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39melasticsearch\u001b[39;00m \u001b[39mimport\u001b[39;00m Elasticsearch\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39melasticsearch_dsl\u001b[39;00m \u001b[39mimport\u001b[39;00m Search\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n",
      "File \u001b[0;32m~/Projets/NLP/psycho_NLP/venv/lib/python3.10/site-packages/elasticsearch_dsl/__init__.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maggs\u001b[39;00m \u001b[39mimport\u001b[39;00m A\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39manalysis\u001b[39;00m \u001b[39mimport\u001b[39;00m analyzer, char_filter, normalizer, token_filter, tokenizer\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdocument\u001b[39;00m \u001b[39mimport\u001b[39;00m Document, InnerDoc, MetaField\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     ElasticsearchDslException,\n\u001b[1;32m     24\u001b[0m     IllegalOperation,\n\u001b[1;32m     25\u001b[0m     UnknownDslObject,\n\u001b[1;32m     26\u001b[0m     ValidationException,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfaceted_search\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     DateHistogramFacet,\n\u001b[1;32m     30\u001b[0m     Facet,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     TermsFacet,\n\u001b[1;32m     37\u001b[0m )\n",
      "File \u001b[0;32m~/Projets/NLP/psycho_NLP/venv/lib/python3.10/site-packages/elasticsearch_dsl/document.py:31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m IllegalOperation, ValidationException\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfield\u001b[39;00m \u001b[39mimport\u001b[39;00m Field\n\u001b[0;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mindex\u001b[39;00m \u001b[39mimport\u001b[39;00m Index\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmapping\u001b[39;00m \u001b[39mimport\u001b[39;00m Mapping\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msearch\u001b[39;00m \u001b[39mimport\u001b[39;00m Search\n",
      "File \u001b[0;32m~/Projets/NLP/psycho_NLP/venv/lib/python3.10/site-packages/elasticsearch_dsl/index.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m IllegalOperation\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmapping\u001b[39;00m \u001b[39mimport\u001b[39;00m Mapping\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msearch\u001b[39;00m \u001b[39mimport\u001b[39;00m Search\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mupdate_by_query\u001b[39;00m \u001b[39mimport\u001b[39;00m UpdateByQuery\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m merge\n",
      "File \u001b[0;32m~/Projets/NLP/psycho_NLP/venv/lib/python3.10/site-packages/elasticsearch_dsl/search.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mcollections_abc\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39melasticsearch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m TransportError\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39melasticsearch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhelpers\u001b[39;00m \u001b[39mimport\u001b[39;00m scan\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msix\u001b[39;00m \u001b[39mimport\u001b[39;00m iteritems, string_types\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maggs\u001b[39;00m \u001b[39mimport\u001b[39;00m A, AggBase\n",
      "File \u001b[0;32m~/Projets/NLP/psycho_NLP/venv/lib/python3.10/site-packages/elasticsearch/helpers/__init__.py:20\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#  Licensed to Elasticsearch B.V. under one or more contributor\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#  license agreements. See the NOTICE file distributed with\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#  this work for additional information regarding copyright\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m#  specific language governing permissions and limitations\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m#  under the License.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mactions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     _chunk_actions,\n\u001b[1;32m     22\u001b[0m     _process_bulk_chunk,\n\u001b[1;32m     23\u001b[0m     bulk,\n\u001b[1;32m     24\u001b[0m     expand_action,\n\u001b[1;32m     25\u001b[0m     parallel_bulk,\n\u001b[1;32m     26\u001b[0m     reindex,\n\u001b[1;32m     27\u001b[0m     scan,\n\u001b[1;32m     28\u001b[0m     streaming_bulk,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39merrors\u001b[39;00m \u001b[39mimport\u001b[39;00m BulkIndexError, ScanError\n\u001b[1;32m     32\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     33\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mBulkIndexError\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mScanError\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_process_bulk_chunk\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m ]\n",
      "File \u001b[0;32m~/Projets/NLP/psycho_NLP/venv/lib/python3.10/site-packages/elasticsearch/helpers/actions.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39moperator\u001b[39;00m \u001b[39mimport\u001b[39;00m methodcaller\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m Mapping, Queue, \u001b[39mmap\u001b[39m, string_types\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m NotFoundError, TransportError\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39merrors\u001b[39;00m \u001b[39mimport\u001b[39;00m BulkIndexError, ScanError\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Mapping' from 'elasticsearch.compat' (/home/apprenant/Projets/NLP/psycho_NLP/venv/lib/python3.10/site-packages/elasticsearch/compat.py)"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}]) # replace with your own host and port\n",
    "\n",
    "# 1. Requête pour obtenir la répartition des sentiments pour un patient\n",
    "def get_patient_sentiment_distribution(first_name, last_name):\n",
    "    s = Search(using=es, index=\"your_index\")         .query(\"match\", first_name=first_name)         .query(\"match\", last_name=last_name)         .aggs.bucket('sentiments', 'terms', field='sentiment')\n",
    "    response = s.execute()\n",
    "    df = pd.DataFrame(response.aggregations.sentiments.buckets)\n",
    "    df.columns = ['sentiment', 'count']\n",
    "    return df\n",
    "\n",
    "# 2. Matrice des sentiments contradictoires\n",
    "def get_sentiment_matrix():\n",
    "    sentiments = ['happy', 'sadness', 'fear', 'anger', 'surprise', 'neutral']\n",
    "    matrix = pd.DataFrame(index=sentiments, columns=sentiments)\n",
    "    for sentiment in sentiments:\n",
    "        for word in sentiments:\n",
    "            s = Search(using=es, index=\"your_index\")                 .query(\"match\", sentiment=sentiment)                 .query(\"match\", text=word)\n",
    "            response = s.execute()\n",
    "            matrix.loc[sentiment, word] = response.hits.total['value'] / response.hits.max_score\n",
    "    sns.heatmap(matrix, annot=True, cmap='YlGnBu')\n",
    "    plt.show()\n",
    "\n",
    "# 3. Rechercher le nombre de textes correspondants aux étapes du deuil\n",
    "def get_grief_stage_counts():\n",
    "    stages = ['denial', 'anger', 'bargaining', 'depression', 'acceptance']\n",
    "    counts = {}\n",
    "    for stage in stages:\n",
    "        # Full text search\n",
    "        s = Search(using=es, index=\"your_index\").query(\"match\", text=stage)\n",
    "        response = s.execute()\n",
    "        counts[stage] = {\n",
    "            'full_search': response.hits.total['value'],\n",
    "            'fuzzy_search': 0\n",
    "        }\n",
    "        # Fuzzy search\n",
    "        s = Search(using=es, index=\"your_index\").query(\"fuzzy\", text={\"value\": stage})\n",
    "        response = s.execute()\n",
    "        counts[stage]['fuzzy_search'] = response.hits.total['value']\n",
    "    return pd.DataFrame(counts)\n",
    "\n",
    "# 4. Rechercher les textes avec les conditions données\n",
    "def get_filtered_texts():\n",
    "    s = Search(using=es, index=\"your_index\")         .query(\"match_phrase\", text=\"good day\")         .filter(\"term\", in_consultation=True)         .should(\"match_phrase\", text=\"to rest\")         .exclude(\"range\", confidence={\"lt\": 0.5})\n",
    "    response = s.execute()\n",
    "    df = pd.DataFrame((hit.to_dict() for hit in response), columns=['text', 'sentiment', 'confidence'])\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
